{"cells":[{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":["## Pyspark Window Functions\n\nPyspark window functions are useful when you want to examine relationships within groups of data rather than between groups of data (as for groupBy)\n\nTo use them you start by defining a window function then select a separate function or set of functions to operate within that window\n\nNB- this workbook is designed to work on Databricks Community Edition"],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\nimport pyspark.sql.functions as fn\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql import Window"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["# Create a spark session\nspark_session = SparkSession.builder.getOrCreate()\n\n# lets define a demonstration DataFrame to work on\ndf_data = {'partition': ['a','a', 'a', 'a', 'b', 'b', 'b', 'c', 'c',],\n           'col_1': [1,1,1,1,2,2,2,3,3,], \n           'aggregation': [1,2,3,4,5,6,7,8,9,],\n           'ranking': [4,3,2,1,1,1,3,1,5,],\n           'lagging': [9,8,7,6,5,4,3,2,1,],\n           'cumulative': [1,2,4,6,1,1,1,20,30,],\n          }\ndf_pandas = pd.DataFrame.from_dict(df_data)\n# create spark dataframe\ndf = spark_session.createDataFrame(df_pandas)\n\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+-----+-----------+-------+-------+----------+\npartition|col_1|aggregation|ranking|lagging|cumulative|\n+---------+-----+-----------+-------+-------+----------+\n        a|    1|          1|      4|      9|         1|\n        a|    1|          2|      3|      8|         2|\n        a|    1|          3|      2|      7|         4|\n        a|    1|          4|      1|      6|         6|\n        b|    2|          5|      1|      5|         1|\n        b|    2|          6|      1|      4|         1|\n        b|    2|          7|      3|      3|         1|\n        c|    3|          8|      1|      2|        20|\n        c|    3|          9|      5|      1|        30|\n+---------+-----+-----------+-------+-------+----------+\n\n</div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["## Simple aggregation functions\n\nwe can use the standard group by aggregations with window functions. These functions use the simplest form of window which just defines grouping"],"metadata":{}},{"cell_type":"code","source":["# aggregation functions use the simplest form of window which just defines grouping\naggregation_window = Window.partitionBy('partition')\n\n# then we can use this window function for our aggregations\ndf_aggregations = df.select(\n  'partition', 'aggregation'\n).withColumn(\n  'aggregation_sum', fn.sum('aggregation').over(aggregation_window),\n).withColumn(\n  'aggregation_avg', fn.avg('aggregation').over(aggregation_window),\n).withColumn(\n  'aggregation_min', fn.min('aggregation').over(aggregation_window),\n).withColumn(\n  'aggregation_max', fn.max('aggregation').over(aggregation_window),\n)\n\ndf_aggregations.show()\n# note that after this operation the row order of display within the dataframe may have changed"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+-----------+---------------+---------------+---------------+---------------+\npartition|aggregation|aggregation_sum|aggregation_avg|aggregation_min|aggregation_max|\n+---------+-----------+---------------+---------------+---------------+---------------+\n        c|          8|             17|            8.5|              8|              9|\n        c|          9|             17|            8.5|              8|              9|\n        b|          5|             18|            6.0|              5|              7|\n        b|          6|             18|            6.0|              5|              7|\n        b|          7|             18|            6.0|              5|              7|\n        a|          1|             10|            2.5|              1|              4|\n        a|          2|             10|            2.5|              1|              4|\n        a|          3|             10|            2.5|              1|              4|\n        a|          4|             10|            2.5|              1|              4|\n+---------+-----------+---------------+---------------+---------------+---------------+\n\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["# \n# df_aggregations = df.select(\n#   'partition, 'ranking'\n# ).withColumn(\n#   'sum_col_3', fn.sum('col_3').over(aggregation_window),\n# ).withColumn(\n#   'avg_col_3', fn.avg('col_3').over(aggregation_window),\n# ).withColumn(\n#   'min_col_3', fn.min('col_3').over(aggregation_window),\n# ).withColumn(\n#   'max_col_3', fn.max('col_3').over(aggregation_window),\n# )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["## Row wise ordering and ranking functions\n\nWe can also use window funtions to order and rank data. These functions add an element to the definition of the window which defines both grouping AND ordering"],"metadata":{}},{"cell_type":"code","source":["# lets define a ranking window\nranking_window = Window.partitionBy('partition').orderBy('ranking')\n\ndf_ranks = df.select(\n  'partition', 'ranking'\n).withColumn(\n  # note that fn.row_number() does not take any arguments\n  'ranking_row_number', fn.row_number().over(ranking_window) \n).withColumn(\n  # rank will leave spaces in ranking to account for preceding rows receiving equal ranks\n  'ranking_rank', fn.rank().over(ranking_window)\n).withColumn(\n  # dense rank does not account for previous equal rankings\n  'ranking_dense_rank', fn.dense_rank().over(ranking_window)\n).withColumn(\n  # percent rank ranges between 0-1 not 0-100\n  'ranking_percent_rank', fn.percent_rank().over(ranking_window)\n).withColumn(\n  # fn.ntile takes a parameter for now many 'buckets' to divide rows into when ranking\n  'ranking_ntile_rank', fn.ntile(2).over(ranking_window)\n)\n\ndf_ranks.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+-------+------------------+------------+------------------+--------------------+------------------+\npartition|ranking|ranking_row_number|ranking_rank|ranking_dense_rank|ranking_percent_rank|ranking_ntile_rank|\n+---------+-------+------------------+------------+------------------+--------------------+------------------+\n        c|      1|                 1|           1|                 1|                 0.0|                 1|\n        c|      5|                 2|           2|                 2|                 1.0|                 2|\n        b|      1|                 1|           1|                 1|                 0.0|                 1|\n        b|      1|                 2|           1|                 1|                 0.0|                 1|\n        b|      3|                 3|           3|                 2|                 1.0|                 2|\n        a|      1|                 1|           1|                 1|                 0.0|                 1|\n        a|      2|                 2|           2|                 2|  0.3333333333333333|                 1|\n        a|      3|                 3|           3|                 3|  0.6666666666666666|                 2|\n        a|      4|                 4|           4|                 4|                 1.0|                 2|\n+---------+-------+------------------+------------+------------------+--------------------+------------------+\n\n</div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["## Creating lagged columns\n\nIf we want to conduct operations like calculating the difference between subsequent operations in a group, we can use window functions to create the lagged values we require to perform the calculation. Where there is no preceding lag value, a null entry will be inserted not a zero.\n\nThe inverse of lag is lead. Effectively fn.lag(n) == fn.lead(-n)"],"metadata":{}},{"cell_type":"code","source":["lag_window = Window.partitionBy('partition').orderBy('lagging')\n\ndf_lagged = df.select(\n  'partition', 'lagging'\n).withColumn(\n  # note that lag requires both column and lag amount to be specified\n  # It is possible to lag a column which was not the orderBy column\n  'lagging_lag_1', fn.lag('lagging', 1).over(lag_window)\n).withColumn(\n  'lagging_lag_2', fn.lag('lagging', 2).over(lag_window)\n).withColumn(\n  'lagging_lead_1', fn.lead('lagging', 1).over(lag_window)\n).withColumn(\n  # note how 'lagging_lag_1' == 'lagging_lead_minus_1'\n  'lagging_lead_minus_1', fn.lead('lagging', -1).over(lag_window)\n).withColumn(\n  # we can also perform calculations between lagged and unlagged columns of course\n  'difference_between', fn.col('lagging') - fn.lag('lagging', 1).over(lag_window)\n)\n\ndf_lagged.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+-------+-------------+-------------+--------------+--------------------+------------------+\npartition|lagging|lagging_lag_1|lagging_lag_2|lagging_lead_1|lagging_lead_minus_1|difference_between|\n+---------+-------+-------------+-------------+--------------+--------------------+------------------+\n        c|      1|         null|         null|             2|                null|              null|\n        c|      2|            1|         null|          null|                   1|                 1|\n        b|      3|         null|         null|             4|                null|              null|\n        b|      4|            3|         null|             5|                   3|                 1|\n        b|      5|            4|            3|          null|                   4|                 1|\n        a|      6|         null|         null|             7|                null|              null|\n        a|      7|            6|         null|             8|                   6|                 1|\n        a|      8|            7|            6|             9|                   7|                 1|\n        a|      9|            8|            7|          null|                   8|                 1|\n+---------+-------+-------------+-------------+--------------+--------------------+------------------+\n\n</div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["### Cumulative Calculations (Running totals and averages)\n\nThere are often good reasons to want to create a running total or running average column. In some cases we might want running totals for subsets of data. Window functions can be useful for that sort of thing. \n\nIn order to calculate such things we need to add yet another element to the window. Now we account for partition, order and which rows should be covered by the function. This can be done in two ways we can use **rangeBetween** to define how similar values in the window must be to be considered, or we can use **rowsBetween** to define how many rows should be considered. The current row is considered row zero, the following rows are numbered positively and the preceding rows negatively. For cumulative calculations you can define \"all previous rows\" with **Window.unboundedPreceding** and \"all following rows\" with **Window.unboundedFolowing**\n\nNote that the window may vary in size as it progresses over the rows since at the start and end part of the window may \"extend past\" the existing rows"],"metadata":{}},{"cell_type":"code","source":["#suppose we want to average over the previous, current and next values\n# running calculations need a more complicated window as shown here\ncumulative_window_1 = Window.partitionBy(\n  'partition'\n).orderBy(\n  'cumulative'\n# for a rolling average lets use rowsBetween\n).rowsBetween(\n  -1,1\n)\n\ndf_cumulative_1 = df.select(\n  'partition', 'cumulative'\n).withColumn(\n  'cumulative_avg', fn.avg('cumulative').over(cumulative_window_1)\n)\n\ndf_cumulative_1.show()\n# note how the averages don't use 3 rows at the ends of the window"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+----------+------------------+\npartition|cumulative|    cumulative_avg|\n+---------+----------+------------------+\n        c|        20|              25.0|\n        c|        30|              25.0|\n        b|         1|               1.0|\n        b|         1|               1.0|\n        b|         1|               1.0|\n        a|         1|               1.5|\n        a|         2|2.3333333333333335|\n        a|         4|               4.0|\n        a|         6|               5.0|\n+---------+----------+------------------+\n\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["# running totals also require a more complicated window as here. \ncumulative_window_2 = Window.partitionBy(\n  'partition'\n).orderBy(\n  'cumulative'\n# in this case we will use rangeBetween for the sum\n).rangeBetween(\n# In this case we need to use Window.unboundedPreceding to catch all earlier rows\n  Window.unboundedPreceding, 0\n)\n\ndf_cumulative_2 = df.select(\n  'partition', 'cumulative'\n).withColumn(\n  'cumulative_sum', fn.sum('cumulative').over(cumulative_window_2)\n)\n\ndf_cumulative_2.show()\n# note the summing behaviour where multiple identical values are present in the orderBy column"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+----------+--------------+\npartition|cumulative|cumulative_sum|\n+---------+----------+--------------+\n        c|        20|            20|\n        c|        30|            50|\n        b|         1|             3|\n        b|         1|             3|\n        b|         1|             3|\n        a|         1|             1|\n        a|         2|             3|\n        a|         4|             7|\n        a|         6|            13|\n+---------+----------+--------------+\n\n</div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["## Combining Windows and Calling Different Columns\nIt is also possible to combine windows and also to call windows on columns other than the ordering column. These more advanced uses can require careful thought to ensure you achieve the intended results"],"metadata":{}},{"cell_type":"code","source":["# we can make a window function equivalent to a standard groupBy:\n\n# first define two windows\naggregation_window = Window.partitionBy('partition')\ngrouping_window = Window.partitionBy('partition').orderBy('aggregation')\n\n# then we can use this window function for our aggregations\ndf_aggregations = df.select(\n  'partition', 'aggregation'\n).withColumn(\n  # note that we calculate row number over the grouping_window\n  'group_rank', fn.row_number().over(grouping_window) \n).withColumn(\n  # but we calculate other columns over the aggregation_window\n  'aggregation_sum', fn.sum('aggregation').over(aggregation_window),\n).withColumn(\n  'aggregation_avg', fn.avg('aggregation').over(aggregation_window),\n).withColumn(\n  'aggregation_min', fn.min('aggregation').over(aggregation_window),\n).withColumn(\n  'aggregation_max', fn.max('aggregation').over(aggregation_window),\n).where(\n  fn.col('group_rank') == 1\n).select(\n  'partition', \n  'aggregation_sum', \n  'aggregation_avg', \n  'aggregation_min', \n  'aggregation_max'\n)\n\ndf_aggregations.show()\n\n# this is equivalent to the rather simpler expression below\ndf_groupby = df.select(\n  'partition', 'aggregation'\n).groupBy(\n  'partition'\n).agg(\n  fn.sum('aggregation').alias('aggregation_sum'),\n  fn.avg('aggregation').alias('aggregation_avg'),\n  fn.min('aggregation').alias('aggregation_min'),\n  fn.max('aggregation').alias('aggregation_max'),\n)\n\ndf_groupby.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+---------------+---------------+---------------+---------------+\npartition|aggregation_sum|aggregation_avg|aggregation_min|aggregation_max|\n+---------+---------------+---------------+---------------+---------------+\n        c|             17|            8.5|              8|              9|\n        b|             18|            6.0|              5|              7|\n        a|             10|            2.5|              1|              4|\n+---------+---------------+---------------+---------------+---------------+\n\n+---------+---------------+---------------+---------------+---------------+\npartition|aggregation_sum|aggregation_avg|aggregation_min|aggregation_max|\n+---------+---------------+---------------+---------------+---------------+\n        c|             17|            8.5|              8|              9|\n        b|             18|            6.0|              5|              7|\n        a|             10|            2.5|              1|              4|\n+---------+---------------+---------------+---------------+---------------+\n\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["# in some cases we can create a window on one column but use the window on another column \n# note that only functions where the column is specified allow this\nlag_window = Window.partitionBy('partition').orderBy('lagging')\n\ndf_cumulative_2 = df.select(\n  'partition', 'lagging', 'cumulative',\n).withColumn(\n  'lag_the_laggging_col', fn.lag('lagging', 1).over(lag_window)\n).withColumn(\n  # It is possible to lag a column which was not the orderBy column\n  'lag_the_cumulative_col', fn.lag('cumulative', 1).over(lag_window)\n)\n\ndf_cumulative_2.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+-------+----------+--------------------+----------------------+\npartition|lagging|cumulative|lag_the_laggging_col|lag_the_cumulative_col|\n+---------+-------+----------+--------------------+----------------------+\n        c|      1|        30|                null|                  null|\n        c|      2|        20|                   1|                    30|\n        b|      3|         1|                null|                  null|\n        b|      4|         1|                   3|                     1|\n        b|      5|         1|                   4|                     1|\n        a|      6|         6|                null|                  null|\n        a|      7|         4|                   6|                     6|\n        a|      8|         2|                   7|                     4|\n        a|      9|         1|                   8|                     2|\n+---------+-------+----------+--------------------+----------------------+\n\n</div>"]}}],"execution_count":17}],"metadata":{"name":"PySpark Window Functions","notebookId":157591980591166},"nbformat":4,"nbformat_minor":0}
